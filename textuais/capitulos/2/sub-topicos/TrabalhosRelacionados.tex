\section{Trabalhos Relacionados}
    \label{sec:related-works}
    
    \citeonline{rodrigues2013selftraining, rodrigues2014selftraining, tao2018selftraining} e \citeonline{vale2018selftraining} propõem pesquisas que fazem uso do algoritmo \textit{Self\hyp{Training}} para problemas de classificação de rótulo único ou multi\hyp{rótulo}.
    
    Em~\citeonline{rodrigues2013selftraining} foi utilizado o algoritmo \textit{Self\hyp{Training}} com métodos propostos pelos próprios autores para a classificação multirrótulo. O trabalho propoz reduzir a aleatoriedade da escolha dos exemplos durante o processo de rotulagem, fazendo uso de um limiar, aliado ao fator de confiança (o pertencimento de um exemplo a sua classe) para decidir se a instância deveria ir para o conjunto dos rotulados, ou não. Por fim, foi realizada uma análise comparativa entre os três métodos, utilizando\hyp{se} cinco bases com seis métricas de avaliação. 
    
    \citeonline{rodrigues2014selftraining} identificaram que o uso do limiar de inclusão causou uma limitação no número de instâncias adicionadas, uma vez que uma quantidade bem menor de instâncias é adicionada, necessitando assim de uma quantidade maior de iterações. Como solução, foi proposto retirar esse limiar e fazer uso apenas do fator de confiança, ordenando os exemplos de forma decrescente com base nesse valor e selecionando \textit{x} exemplos por iteração.
    
    Em~\citeonline{tanha2017semi}, os autores apresentaram que uma árvore de decisão (classificador supervisionado) não produz boas estimativas de probabilidade para as previsões quando aplicadas ao \textit{Self\hyp{Training}}. Foram desenvolvidas várias modificações nesse classificador com a finalidade de produzir uma estimativa melhor. As técnicas utilizadas foram: i) não poda da árvore; ii) correção de \textit{Laplace}; iii) uma medida baseada em distância. 
    
    Em~\citeonline{tao2018selftraining}, foi proposto uma modificação do \textit{Self\hyp{Training}}, os autores utilizam dados rotulados e não rotulados para realizar a classificação dos dados, além de utilizar duas medidas para auxiliar o algoritmo, sendo elas: i) um método baseado na caminhada aleatória, utilizado junto ao classificador para gerar previsões confiáveis nos dados não rotulados ii) o sub\hyp{conjunto} ótimo $U'$ que gera mais instâncias no conjunto de treinamento.
    
    No trabalho de~\citeonline{vale2018selftraining}, foi realizada uma comparação entre o algoritmo \textit{Self\hyp{Training}} e três variações desse algoritmo propostos pelos autores. Essas variações diferenciam\hyp{se} por realizarem uma nova forma de calcular o limiar controlado dinamicamente, incluindo assim novos exemplos no conjunto dos rotulados. Os resultados das variações propostas obtiveram taxas de acerto melhores que o algoritmo do \textit{Self\hyp{Training}} utilizado nos testes. 
    
    % O foco desta pesquisa é realizar uma análise comparativa de dois algoritmos propostos em \citeonline{vale2018selftraining}. Diferindo\hyp{se} por utilizar diferentes valores para a variação do limiar e aplicando a quatro classificadores sendo eles: rpartXse, Naive Bayes, \ac{knn} e \ac{ripper}.
    
    
    O foco desta pesquisa é realizar uma análise comparativa de dois algoritmos propostos em \citeonline{vale2018selftraining} que utiliza um classificador para avaliar se o limiar é alterado ou não. Diferindo\hyp{se} por realizar uma análise dos efeitos de diferentes valores aplicados a taxa de variação do limiar, para avaliar as acurácias obtidas pelos classificadores: Na\"ive Bayes, \textit{rpartXse}, \ac{knn} e \ac{ripper}.